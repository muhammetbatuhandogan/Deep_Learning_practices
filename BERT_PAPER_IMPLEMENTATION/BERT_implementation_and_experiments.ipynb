{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1cd476a-c063-49cf-8614-28f6e07d30e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "    num_rows: 14041\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "    num_rows: 3250\n",
      "})\n",
      "Dataset({\n",
      "    features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "    num_rows: 3453\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"conll2003\")\n",
    "\n",
    "\n",
    "train_dataset = dataset[\"train\"]\n",
    "validation_dataset = dataset[\"validation\"]\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "print(train_dataset)\n",
    "print(validation_dataset)\n",
    "print(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e87b8e22-f5f0-424c-9466-22a403fa7219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Experiment configuration ready.\n",
      "model_name          : bert-base-cased\n",
      "num_epochs          : 3\n",
      "batch_size          : 16\n",
      "learning_rate       : 2e-05\n",
      "max_length          : 128\n",
      "weight_decay        : 0.01\n",
      "warmup_ratio        : 0.1\n",
      "fp16                : True\n",
      "save_dir            : C:\\Users\\mbdn1\\models\\finetuned_20251115_115320\n",
      "results_file        : C:\\Users\\mbdn1\\results\\results_20251115_115320.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Experiment Configuration (fixed paths)\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Root directory = current notebook folder \n",
    "PROJECT_ROOT = os.getcwd()\n",
    "\n",
    "# Safer local subdirectories\n",
    "DATA_DIR     = os.path.join(PROJECT_ROOT, \"data\")\n",
    "MODELS_DIR   = os.path.join(PROJECT_ROOT, \"models\")\n",
    "RESULTS_DIR  = os.path.join(PROJECT_ROOT, \"results\")\n",
    "\n",
    "for path in [DATA_DIR, MODELS_DIR, RESULTS_DIR]:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "experiment_config = {\n",
    "    \"model_name\": \"bert-base-cased\",\n",
    "    \"num_epochs\": 3,\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"max_length\": 128,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \"fp16\": True,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, f\"finetuned_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, f\"results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"),\n",
    "}\n",
    "\n",
    "print(\" Experiment configuration ready.\")\n",
    "for k, v in experiment_config.items():\n",
    "    print(f\"{k:20s}: {v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11f30d9f-24b9-461b-9b7c-05e673b3b82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n",
      "\n",
      "Sample from train split:\n",
      "Tokens     : ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "NER tags   : [3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "\n",
      "Tokenized input IDs: [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913, 119, 102]\n",
      "Decoded tokens     : ['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "#  Load CoNLL-2003 Dataset & Tokenizer\n",
    "# ============================================\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load dataset \n",
    "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "# Initialize tokenizer for BERT-base-cased\n",
    "tokenizer = AutoTokenizer.from_pretrained(experiment_config[\"model_name\"])\n",
    "\n",
    "# Display dataset splits\n",
    "print(dataset)\n",
    "\n",
    "# Peek at one example\n",
    "sample = dataset[\"train\"][0]\n",
    "print(\"\\nSample from train split:\")\n",
    "print(f\"Tokens     : {sample['tokens']}\")\n",
    "print(f\"NER tags   : {sample['ner_tags']}\")\n",
    "\n",
    "# Show what tokenization looks like\n",
    "tokenized = tokenizer(sample[\"tokens\"], is_split_into_words=True)\n",
    "print(\"\\nTokenized input IDs:\", tokenized[\"input_ids\"][:20])\n",
    "print(\"Decoded tokens     :\", tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"])[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bff5090-8668-492e-98c1-35620fe348ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NER label mapping:\n",
      "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2f5c7093b5d4ab5a72bbafe50904160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing and aligning labels:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62bd6efe1713436b8d21330e027b3392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing and aligning labels:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "364249b4866f4609ad590353b9f40d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing and aligning labels:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenization and label alignment complete!\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n",
      "\n",
      "Example tokenized entry:\n",
      "{'tokens': ['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.'], 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7], 'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0], 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0], 'input_ids': [101, 7270, 22961, 1528, 1840, 1106, 21423, 1418, 2495, 12913], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 3, 0, 7, 0, 0, 0, 7, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "#  Tokenization + Label Alignment\n",
    "# ============================================\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Extract label info from the dataset\n",
    "ner_feature = dataset[\"train\"].features[\"ner_tags\"].feature\n",
    "id2label = {i: label for i, label in enumerate(ner_feature.names)}\n",
    "label2id = {label: i for i, label in enumerate(ner_feature.names)}\n",
    "\n",
    "print(\"NER label mapping:\")\n",
    "print(id2label)\n",
    "\n",
    "# ---- Tokenize + align labels ---- #\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=experiment_config[\"max_length\"],\n",
    "    )\n",
    "\n",
    "    aligned_labels = []\n",
    "    for i, labels in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)  # ignore special tokens\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(labels[word_idx])  # label for first subtoken\n",
    "            else:\n",
    "                \n",
    "                label_name = id2label[labels[word_idx]]\n",
    "                if label_name.startswith(\"B-\"):\n",
    "                    label_ids.append(label2id[\"I-\" + label_name[2:]])\n",
    "                else:\n",
    "                    label_ids.append(labels[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        aligned_labels.append(label_ids)\n",
    "\n",
    "    tokenized[\"labels\"] = aligned_labels\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "# Apply the function to all splits\n",
    "tokenized_datasets = dataset.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    desc=\"Tokenizing and aligning labels\",\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\\nTokenization and label alignment complete!\")\n",
    "print(tokenized_datasets)\n",
    "print(\"\\nExample tokenized entry:\")\n",
    "example = tokenized_datasets[\"train\"][0]\n",
    "print({k: v[:10] for k, v in example.items() if isinstance(v, list)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3832225-3c25-47c5-8480-f0a4b961cd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Reusable Fine-Tuning Function (Final Version)\n",
    "# ============================================\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForTokenClassification,\n",
    "    DataCollatorForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    ")\n",
    "import numpy as np\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "# --- metric function ---\n",
    "def compute_metrics(p):\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=-1)\n",
    "    true_preds, true_labels = [], []\n",
    "\n",
    "    for pred_seq, label_seq in zip(preds, labels):\n",
    "        cur_preds, cur_labels = [], []\n",
    "        for p_id, l_id in zip(pred_seq, label_seq):\n",
    "            if l_id == -100:\n",
    "                continue\n",
    "            cur_preds.append(id2label[p_id])\n",
    "            cur_labels.append(id2label[l_id])\n",
    "        true_preds.append(cur_preds)\n",
    "        true_labels.append(cur_labels)\n",
    "\n",
    "    return {\n",
    "        \"precision\": precision_score(true_labels, true_preds),\n",
    "        \"recall\": recall_score(true_labels, true_preds),\n",
    "        \"f1\": f1_score(true_labels, true_preds),\n",
    "    }\n",
    "\n",
    "\n",
    "# --- reusable training function ---\n",
    "def run_finetuning(config, tokenized_datasets):\n",
    "    \"\"\"\n",
    "    Fine-tune BERT on CoNLL-2003 using parameters in `config`.\n",
    "    Saves model + metrics automatically.\n",
    "    \"\"\"\n",
    "    print(f\"\\nStarting fine-tuning for {config['model_name']}\")\n",
    "    os.makedirs(config[\"save_dir\"], exist_ok=True)\n",
    "\n",
    "    # Load model\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\n",
    "        config[\"model_name\"],\n",
    "        num_labels=len(id2label),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    # Collator for dynamic padding\n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "    # Training arguments \n",
    "    try:\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=config[\"save_dir\"],\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=config[\"learning_rate\"],\n",
    "            per_device_train_batch_size=config[\"batch_size\"],\n",
    "            per_device_eval_batch_size=config[\"batch_size\"],\n",
    "            num_train_epochs=config[\"num_epochs\"],\n",
    "            weight_decay=config[\"weight_decay\"],\n",
    "            warmup_ratio=config[\"warmup_ratio\"],\n",
    "            logging_steps=50,\n",
    "            report_to=\"none\",\n",
    "            fp16=config[\"fp16\"],\n",
    "            save_total_limit=2,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            greater_is_better=True,\n",
    "        )\n",
    "    except TypeError:\n",
    "        # fallback for older Transformers versions\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=config[\"save_dir\"],\n",
    "            do_eval=True,\n",
    "            learning_rate=config[\"learning_rate\"],\n",
    "            per_device_train_batch_size=config[\"batch_size\"],\n",
    "            per_device_eval_batch_size=config[\"batch_size\"],\n",
    "            num_train_epochs=config[\"num_epochs\"],\n",
    "            weight_decay=config[\"weight_decay\"],\n",
    "            warmup_ratio=config[\"warmup_ratio\"],\n",
    "            logging_steps=50,\n",
    "            report_to=\"none\",\n",
    "            fp16=config[\"fp16\"],\n",
    "        )\n",
    "\n",
    "    # ---- Trainer ----\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets[\"train\"],\n",
    "        eval_dataset=tokenized_datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    # ---- Train and evaluate ----\n",
    "    trainer.train()\n",
    "    metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "    print(\"\\nTest metrics:\", metrics)\n",
    "\n",
    "    # ---- Save model + results ----\n",
    "    trainer.save_model(config[\"save_dir\"])\n",
    "    with open(config[\"results_file\"], \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(f\"\\nðŸ’¾ Results saved to {config['results_file']}\")\n",
    "    print(f\"ðŸ’¾ Model saved to   {config['save_dir']}\")\n",
    "\n",
    "    return trainer, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6428b94-3848-4fec-8fa3-10ad796baef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2634/2634 03:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.120800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.520500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.313400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.177500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.118900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.128100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.126800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.122300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.099200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.079900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.056900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.059400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.049100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.050900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.044400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.054300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.037800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.17203058302402496, 'eval_precision': 0.8833190761334474, 'eval_recall': 0.914776754075124, 'eval_f1': 0.8987727391417878, 'eval_runtime': 5.2981, 'eval_samples_per_second': 651.747, 'eval_steps_per_second': 40.77, 'epoch': 3.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr2e5_ep3_bs16.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr2e5_ep3_bs16\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Start Fine-Tuning (Run 1)\n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run 1\n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"num_epochs\": 3,\n",
    "    \"batch_size\": 16,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr2e5_ep3_bs16\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr2e5_ep3_bs16.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9eb675e-844a-4f22-bccf-764ba7f8d728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2634/2634 04:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.977700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.811200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.227100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.155800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.113200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.119200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.107600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.098300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.067400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.072100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.058900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.043500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.050900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.045600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.031200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.017500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.020200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.021200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.18000313639640808, 'eval_precision': 0.8870386266094421, 'eval_recall': 0.9154854712969526, 'eval_f1': 0.9010375795622985, 'eval_runtime': 6.6775, 'eval_samples_per_second': 517.108, 'eval_steps_per_second': 32.347, 'epoch': 3.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e5_ep3_bs16.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e5_ep3_bs16\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Fine-Tuning Experiment \n",
    "# ============================================\n",
    "\n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 3e-5,   \n",
    "    \"num_epochs\": 3,         \n",
    "    \"batch_size\": 16,        \n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr3e5_ep3_bs16\"),   \n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr3e5_ep3_bs16.json\"), \n",
    "})\n",
    "\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882bc061-d496-4cad-a5b9-3b32cfb8e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4390/4390 07:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.308400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.700700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.441300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.302800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.217400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.145900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.142100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.090800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.107200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.107100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.079100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.074100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.090200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.067900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.053400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.053200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.053800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.061900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.039800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.029700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.033400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.028700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.036000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.005700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.19718238711357117, 'eval_precision': 0.8889270976616231, 'eval_recall': 0.9160170092133239, 'eval_f1': 0.9022687609075044, 'eval_runtime': 6.568, 'eval_samples_per_second': 525.727, 'eval_steps_per_second': 32.887, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr2e5_ep5_bs16.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr2e5_ep5_bs16\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run\n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 16,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr2e5_ep5_bs16\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr2e5_ep5_bs16.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9773894-d131-4616-8427-12d4351107da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4390/4390 07:04, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.089300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.090400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.565900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.331900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.241300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.126600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.135900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.127000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.088200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.107700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.080100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.073400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.083000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.067800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.052100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.053200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.047400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.054100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.045100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.050800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.042000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.054300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.029200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.032300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.028800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.009700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.003500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.2097415030002594, 'eval_precision': 0.8881094952951241, 'eval_recall': 0.9197377746279235, 'eval_f1': 0.9036469666637653, 'eval_runtime': 5.639, 'eval_samples_per_second': 612.347, 'eval_steps_per_second': 38.305, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e5_ep5_bs16.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e5_ep5_bs16\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "#Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run \n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 16,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr3e5_ep5_bs16\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr3e5_ep5_bs16.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80ffc925-f765-4362-a25b-7f341b2da95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2634' max='2634' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2634/2634 04:02, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.803200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.655500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.281700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.194500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.159800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.103100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.112800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.121600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.065800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.092600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.092200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.064300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.068400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.043000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.042100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.044300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.045200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.043300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.017000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.018300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.013500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.1744958758354187, 'eval_precision': 0.8916307161345988, 'eval_recall': 0.9154854712969526, 'eval_f1': 0.903400646909695, 'eval_runtime': 5.614, 'eval_samples_per_second': 615.074, 'eval_steps_per_second': 38.476, 'epoch': 3.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr5e5_ep3_bs16.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr5e5_ep3_bs16\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Start Fine-Tuning (Run 1)\n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run\n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_epochs\": 3,\n",
    "    \"batch_size\": 16,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr5e5_ep3_bs16\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr5e5_ep3_bs16.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "165d36cf-e24d-471d-b058-1cc4abce06cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4390/4390 07:23, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.977000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.810300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.389700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.226900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.190100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.156000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.117700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.125600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.120400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.078800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.070800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.078500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.075600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.082900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.064200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.055900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.060900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.050800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.048300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.051800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.043700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.035100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.024900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.003600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.003200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.21857108175754547, 'eval_precision': 0.8880699348645869, 'eval_recall': 0.9179659815733522, 'eval_f1': 0.9027705175117617, 'eval_runtime': 6.514, 'eval_samples_per_second': 530.088, 'eval_steps_per_second': 33.159, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr5e5_ep5_bs16.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr5e5_ep5_bs16\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "#  Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run \n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 16,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr5e5_ep5_bs16\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr5e5_ep5_bs16.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b293590-0d68-4b5e-a6f2-1b0b91f0e379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 04:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.691000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.095800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.075400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.073100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.051900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.050900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.045400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.020400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.018200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.022100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.18529222905635834, 'eval_precision': 0.8949724517906336, 'eval_recall': 0.9209780297661233, 'eval_f1': 0.9077890324834089, 'eval_runtime': 4.0645, 'eval_samples_per_second': 849.556, 'eval_steps_per_second': 26.572, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr5e5_ep5_bs32.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr5e5_ep5_bs32\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run \n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr5e5_ep5_bs32\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr5e5_ep5_bs32.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5da44ff9-7cd7-4d60-b4a2-aa2d31bd6042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 04:05, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.875200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.717400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.298700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.154900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.088100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.074400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.079200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.056400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.051600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.051300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.049900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.022700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.027400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.010400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.015200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.17884385585784912, 'eval_precision': 0.8884134862228308, 'eval_recall': 0.9197377746279235, 'eval_f1': 0.903804300513624, 'eval_runtime': 4.0075, 'eval_samples_per_second': 861.63, 'eval_steps_per_second': 26.949, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e5_ep5_bs32.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e5_ep5_bs32\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run \n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr3e5_ep5_bs32\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr3e5_ep5_bs32.json\"),\n",
    "})\n",
    "\n",
    "# ðŸš€ Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01036eb0-de09-4a0e-a314-dda470738a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 04:06, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.000400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.887400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.406500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.200300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.164600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.081200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.086600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.065400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.059400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.061000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.057000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.056000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.034700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.034200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.020300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.013000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.17124372720718384, 'eval_precision': 0.8884701045057393, 'eval_recall': 0.9188518781006378, 'eval_f1': 0.9034056266875707, 'eval_runtime': 3.8634, 'eval_samples_per_second': 893.782, 'eval_steps_per_second': 27.955, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr2e5_ep5_bs32.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr2e5_ep5_bs32\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run \n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"num_epochs\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr2e5_ep5_bs32\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr2e5_ep5_bs32.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0415407-e9b6-4661-a0f2-d843c78e28f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1317' max='1317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1317/1317 02:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.522400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.384400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.186800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.114000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.081700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.064200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.068100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.047400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.040900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.046800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.043400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.043600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.15965937077999115, 'eval_precision': 0.8843980133584518, 'eval_recall': 0.9149539333805812, 'eval_f1': 0.8994165287816772, 'eval_runtime': 4.0791, 'eval_samples_per_second': 846.519, 'eval_steps_per_second': 26.477, 'epoch': 3.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr5e5_ep3_bs32.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr5e5_ep3_bs32\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run\n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_epochs\": 3,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr5e5_ep3_bs32\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr5e5_ep3_bs32.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1215566-81a3-426f-982d-cad4c5366007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1317' max='1317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1317/1317 02:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.690400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.505100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.210800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.123100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.126400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.092300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.079300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.070300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.074900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.053400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.049700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.047400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.021700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.020600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.023100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.15105868875980377, 'eval_precision': 0.8841002747252747, 'eval_recall': 0.9122962437987243, 'eval_f1': 0.8979769794209976, 'eval_runtime': 3.9319, 'eval_samples_per_second': 878.197, 'eval_steps_per_second': 27.467, 'epoch': 3.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e5_ep3_bs32.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e5_ep3_bs32\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "#Start Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run \n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"num_epochs\": 3,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr3e5_ep3_bs32\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr3e5_ep3_bs32.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eea20dda-2461-49b6-9341-36d2d4620ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1317' max='1317' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1317/1317 02:27, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.841300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.654900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.273200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.145300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.140300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.075300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.082500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.062000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.057100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.058100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.057400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.053700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.032000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.035800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.028300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.15349237620830536, 'eval_precision': 0.876218156949906, 'eval_recall': 0.9080439404677534, 'eval_f1': 0.8918472113460368, 'eval_runtime': 4.0506, 'eval_samples_per_second': 852.459, 'eval_steps_per_second': 26.662, 'epoch': 3.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr2e5_ep3_bs32.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr2e5_ep3_bs32\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Fine-Tuning \n",
    "# ============================================\n",
    "\n",
    "# Configuration for Run\n",
    "experiment_config.update({\n",
    "    \"learning_rate\": 2e-5,\n",
    "    \"num_epochs\": 3,\n",
    "    \"batch_size\": 32,\n",
    "    \"save_dir\": os.path.join(MODELS_DIR, \"bert_lr2e5_ep3_bs32\"),\n",
    "    \"results_file\": os.path.join(RESULTS_DIR, \"bert_lr2e5_ep3_bs32.json\"),\n",
    "})\n",
    "\n",
    "# Start training\n",
    "trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32318a9b-0f9d-4a9a-b920-b08935f810ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All experiment results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Experiment</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert_lr5e5_ep5_bs32</td>\n",
       "      <td>0.894972</td>\n",
       "      <td>0.920978</td>\n",
       "      <td>0.907789</td>\n",
       "      <td>0.185292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert_lr3e-05_ep5_bs32_seed2025</td>\n",
       "      <td>0.889535</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.176802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_lr3e-05_ep5_bs16_seed2025</td>\n",
       "      <td>0.890800</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.904093</td>\n",
       "      <td>0.202344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert_lr3e5_ep5_bs32</td>\n",
       "      <td>0.888413</td>\n",
       "      <td>0.919738</td>\n",
       "      <td>0.903804</td>\n",
       "      <td>0.178844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert_lr3e5_ep5_bs16</td>\n",
       "      <td>0.888109</td>\n",
       "      <td>0.919738</td>\n",
       "      <td>0.903647</td>\n",
       "      <td>0.209742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert_lr2e5_ep5_bs32</td>\n",
       "      <td>0.888470</td>\n",
       "      <td>0.918852</td>\n",
       "      <td>0.903406</td>\n",
       "      <td>0.171244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert_lr5e5_ep3_bs16</td>\n",
       "      <td>0.891631</td>\n",
       "      <td>0.915485</td>\n",
       "      <td>0.903401</td>\n",
       "      <td>0.174496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert_lr3e-05_ep5_bs16_seed42</td>\n",
       "      <td>0.887710</td>\n",
       "      <td>0.918852</td>\n",
       "      <td>0.903012</td>\n",
       "      <td>0.216410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert_lr5e5_ep5_bs16</td>\n",
       "      <td>0.888070</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.902771</td>\n",
       "      <td>0.218571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert_lr2e5_ep5_bs16</td>\n",
       "      <td>0.888927</td>\n",
       "      <td>0.916017</td>\n",
       "      <td>0.902269</td>\n",
       "      <td>0.197182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert_lr3e-05_ep5_bs32_seed42</td>\n",
       "      <td>0.884944</td>\n",
       "      <td>0.918498</td>\n",
       "      <td>0.901408</td>\n",
       "      <td>0.183819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert_lr3e5_ep3_bs16</td>\n",
       "      <td>0.887039</td>\n",
       "      <td>0.915485</td>\n",
       "      <td>0.901038</td>\n",
       "      <td>0.180003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert_lr2e-05_ep5_bs32_seed2025</td>\n",
       "      <td>0.884365</td>\n",
       "      <td>0.916017</td>\n",
       "      <td>0.899913</td>\n",
       "      <td>0.171499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bert_lr5e5_ep3_bs32</td>\n",
       "      <td>0.884398</td>\n",
       "      <td>0.914954</td>\n",
       "      <td>0.899417</td>\n",
       "      <td>0.159659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bert_lr5e-05_ep5_bs32_seed2025</td>\n",
       "      <td>0.882162</td>\n",
       "      <td>0.916549</td>\n",
       "      <td>0.899027</td>\n",
       "      <td>0.187232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>bert_lr2e5_ep3_bs16</td>\n",
       "      <td>0.883319</td>\n",
       "      <td>0.914777</td>\n",
       "      <td>0.898773</td>\n",
       "      <td>0.172031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bert_lr5e-05_ep5_bs32_seed42</td>\n",
       "      <td>0.883430</td>\n",
       "      <td>0.914422</td>\n",
       "      <td>0.898659</td>\n",
       "      <td>0.190067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>bert_lr5e-05_ep5_bs32_seed123</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.914245</td>\n",
       "      <td>0.898016</td>\n",
       "      <td>0.182680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>bert_lr3e5_ep3_bs32</td>\n",
       "      <td>0.884100</td>\n",
       "      <td>0.912296</td>\n",
       "      <td>0.897977</td>\n",
       "      <td>0.151059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bert_lr3e-05_ep5_bs32_seed123</td>\n",
       "      <td>0.880928</td>\n",
       "      <td>0.914954</td>\n",
       "      <td>0.897619</td>\n",
       "      <td>0.180557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>bert_lr2e-05_ep5_bs32_seed42</td>\n",
       "      <td>0.880477</td>\n",
       "      <td>0.914954</td>\n",
       "      <td>0.897385</td>\n",
       "      <td>0.175445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bert_lr3e-05_ep5_bs16_seed123</td>\n",
       "      <td>0.879434</td>\n",
       "      <td>0.913714</td>\n",
       "      <td>0.896246</td>\n",
       "      <td>0.211766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>bert_lr2e-05_ep5_bs32_seed123</td>\n",
       "      <td>0.879563</td>\n",
       "      <td>0.913536</td>\n",
       "      <td>0.896228</td>\n",
       "      <td>0.174224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bert_lr2e5_ep3_bs32</td>\n",
       "      <td>0.876218</td>\n",
       "      <td>0.908044</td>\n",
       "      <td>0.891847</td>\n",
       "      <td>0.153492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Experiment  Precision    Recall        F1      Loss\n",
       "0              bert_lr5e5_ep5_bs32   0.894972  0.920978  0.907789  0.185292\n",
       "1   bert_lr3e-05_ep5_bs32_seed2025   0.889535  0.921687  0.905325  0.176802\n",
       "2   bert_lr3e-05_ep5_bs16_seed2025   0.890800  0.917789  0.904093  0.202344\n",
       "3              bert_lr3e5_ep5_bs32   0.888413  0.919738  0.903804  0.178844\n",
       "4              bert_lr3e5_ep5_bs16   0.888109  0.919738  0.903647  0.209742\n",
       "5              bert_lr2e5_ep5_bs32   0.888470  0.918852  0.903406  0.171244\n",
       "6              bert_lr5e5_ep3_bs16   0.891631  0.915485  0.903401  0.174496\n",
       "7     bert_lr3e-05_ep5_bs16_seed42   0.887710  0.918852  0.903012  0.216410\n",
       "8              bert_lr5e5_ep5_bs16   0.888070  0.917966  0.902771  0.218571\n",
       "9              bert_lr2e5_ep5_bs16   0.888927  0.916017  0.902269  0.197182\n",
       "10    bert_lr3e-05_ep5_bs32_seed42   0.884944  0.918498  0.901408  0.183819\n",
       "11             bert_lr3e5_ep3_bs16   0.887039  0.915485  0.901038  0.180003\n",
       "12  bert_lr2e-05_ep5_bs32_seed2025   0.884365  0.916017  0.899913  0.171499\n",
       "13             bert_lr5e5_ep3_bs32   0.884398  0.914954  0.899417  0.159659\n",
       "14  bert_lr5e-05_ep5_bs32_seed2025   0.882162  0.916549  0.899027  0.187232\n",
       "15             bert_lr2e5_ep3_bs16   0.883319  0.914777  0.898773  0.172031\n",
       "16    bert_lr5e-05_ep5_bs32_seed42   0.883430  0.914422  0.898659  0.190067\n",
       "17   bert_lr5e-05_ep5_bs32_seed123   0.882353  0.914245  0.898016  0.182680\n",
       "18             bert_lr3e5_ep3_bs32   0.884100  0.912296  0.897977  0.151059\n",
       "19   bert_lr3e-05_ep5_bs32_seed123   0.880928  0.914954  0.897619  0.180557\n",
       "20    bert_lr2e-05_ep5_bs32_seed42   0.880477  0.914954  0.897385  0.175445\n",
       "21   bert_lr3e-05_ep5_bs16_seed123   0.879434  0.913714  0.896246  0.211766\n",
       "22   bert_lr2e-05_ep5_bs32_seed123   0.879563  0.913536  0.896228  0.174224\n",
       "23             bert_lr2e5_ep3_bs32   0.876218  0.908044  0.891847  0.153492"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================\n",
    "# Collect and Compare All Results\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect all JSON files in the results directory\n",
    "result_files = glob.glob(os.path.join(RESULTS_DIR, \"*.json\"))\n",
    "\n",
    "all_results = []\n",
    "for file in result_files:\n",
    "    with open(file, \"r\") as f:\n",
    "        metrics = json.load(f)\n",
    "    name = os.path.basename(file).replace(\".json\", \"\")\n",
    "    all_results.append({\n",
    "        \"Experiment\": name,\n",
    "        \"Precision\": metrics.get(\"eval_precision\", None),\n",
    "        \"Recall\": metrics.get(\"eval_recall\", None),\n",
    "        \"F1\": metrics.get(\"eval_f1\", None),\n",
    "        \"Loss\": metrics.get(\"eval_loss\", None),\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "results_df = pd.DataFrame(all_results)\n",
    "results_df = results_df.sort_values(by=\"F1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"All experiment results:\")\n",
    "display(results_df)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(results_df[\"Experiment\"], results_df[\"F1\"], color=\"skyblue\")\n",
    "plt.xlabel(\"F1 Score\")\n",
    "plt.title(\"Fine-Tuning Results Comparison (BERT-base-cased)\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ec946-3fa1-4186-96b5-531fb19b549f",
   "metadata": {},
   "source": [
    "#### we will continue with first 4's hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63e1f079-c164-490f-8148-36e471a6a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Seed part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec3439fe-40ea-4a20-b4b2-3930c1b6fedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total runs: 4 Ã— 3 = 12 experiments\n",
      "\n",
      "\n",
      " Starting run: bert_lr5e-05_ep5_bs32_seed42\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 03:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.703900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.521400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.219500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.073300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.045600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.053600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.046100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.047700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.044400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.019800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.014200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.003300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.006000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.19006654620170593, 'eval_precision': 0.8834303320780554, 'eval_recall': 0.9144223954642098, 'eval_f1': 0.8986592373324046, 'eval_runtime': 3.3253, 'eval_samples_per_second': 1038.391, 'eval_steps_per_second': 32.478, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr5e-05_ep5_bs32_seed42.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr5e-05_ep5_bs32_seed42\n",
      " Finished bert_lr5e-05_ep5_bs32_seed42\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr5e-05_ep5_bs32_seed123\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 03:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.590700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.480400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.123800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.071700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.074400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.051500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.052000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.048400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.047200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.044700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.021000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.1826798915863037, 'eval_precision': 0.8823529411764706, 'eval_recall': 0.9142452161587526, 'eval_f1': 0.898016011138183, 'eval_runtime': 4.2501, 'eval_samples_per_second': 812.447, 'eval_steps_per_second': 25.411, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr5e-05_ep5_bs32_seed123.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr5e-05_ep5_bs32_seed123\n",
      " Finished bert_lr5e-05_ep5_bs32_seed123\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr5e-05_ep5_bs32_seed2025\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 03:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.712700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.507400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.215400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.125800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.127600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.095400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.082500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.075100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.072200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.048500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.059700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.050300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.050100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.041000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.023900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.011000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.003800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.18723200261592865, 'eval_precision': 0.882162346521146, 'eval_recall': 0.9165485471296952, 'eval_f1': 0.8990267639902677, 'eval_runtime': 3.3638, 'eval_samples_per_second': 1026.525, 'eval_steps_per_second': 32.107, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr5e-05_ep5_bs32_seed2025.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr5e-05_ep5_bs32_seed2025\n",
      " Finished bert_lr5e-05_ep5_bs32_seed2025\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr3e-05_ep5_bs32_seed42\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 03:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.721700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.157200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.145100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.100600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.089300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.077300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.078200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.058300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.053100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.053000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.028100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.028500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.016500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.007800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.183818981051445, 'eval_precision': 0.8849436667804712, 'eval_recall': 0.9184975194897236, 'eval_f1': 0.9014084507042254, 'eval_runtime': 3.9305, 'eval_samples_per_second': 878.522, 'eval_steps_per_second': 27.478, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e-05_ep5_bs32_seed42.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e-05_ep5_bs32_seed42\n",
      " Finished bert_lr3e-05_ep5_bs32_seed42\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr3e-05_ep5_bs32_seed123\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 04:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.757700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.668600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.286300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.152300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.141500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.087800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.079700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.059200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.053500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.051000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.052200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.046500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.027800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.028200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.019500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.008000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.008400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.008700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.007600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.18057842552661896, 'eval_precision': 0.8807574206755373, 'eval_recall': 0.914776754075124, 'eval_f1': 0.8974448114027463, 'eval_runtime': 3.7207, 'eval_samples_per_second': 928.049, 'eval_steps_per_second': 29.027, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e-05_ep5_bs32_seed123.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e-05_ep5_bs32_seed123\n",
      " Finished bert_lr3e-05_ep5_bs32_seed123\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr3e-05_ep5_bs32_seed2025\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 04:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.896000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.712800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.281500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.154700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.143700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.105400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.076300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.079100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.055300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.054100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.027600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.022200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.026700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.026800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.023400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.017600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.014600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.016100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.013700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.009200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.1768023520708084, 'eval_precision': 0.8895348837209303, 'eval_recall': 0.9216867469879518, 'eval_f1': 0.9053254437869822, 'eval_runtime': 3.7433, 'eval_samples_per_second': 922.45, 'eval_steps_per_second': 28.852, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e-05_ep5_bs32_seed2025.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e-05_ep5_bs32_seed2025\n",
      " Finished bert_lr3e-05_ep5_bs32_seed2025\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr3e-05_ep5_bs16_seed42\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4390/4390 07:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.121300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.563300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.331200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.236300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.184700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.132700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.138000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.134300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.126500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.090300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.105600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.073800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.088100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.071300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.058500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.052100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.061600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.052600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.047900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.061300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.050500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.040600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.049400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.027700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.023800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.025700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.023600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.024000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.015700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.010200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.019600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.009800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.015800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.016000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.006400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.008500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.005800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.007900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.004100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.002500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.21641035377979279, 'eval_precision': 0.8877096884628551, 'eval_recall': 0.9188518781006378, 'eval_f1': 0.9030123628765454, 'eval_runtime': 6.26, 'eval_samples_per_second': 551.598, 'eval_steps_per_second': 34.505, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e-05_ep5_bs16_seed42.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e-05_ep5_bs16_seed42\n",
      " Finished bert_lr3e-05_ep5_bs16_seed42\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr3e-05_ep5_bs16_seed123\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4390/4390 07:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.953100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.520800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.312600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.242100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.180800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.126400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.121100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.085800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.102100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.076500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.075700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.081200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.064600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.054500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.052800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.054300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.053900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.049300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.054700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.045500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.030500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.031600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.016900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.021900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.019700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.008200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.009000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.017400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.014100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.007700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.003700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.004200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.003400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.006800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.005900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.004700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.2117662876844406, 'eval_precision': 0.8794338335607094, 'eval_recall': 0.9137136782423813, 'eval_f1': 0.8962460896767466, 'eval_runtime': 6.5152, 'eval_samples_per_second': 529.993, 'eval_steps_per_second': 33.153, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e-05_ep5_bs16_seed123.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e-05_ep5_bs16_seed123\n",
      " Finished bert_lr3e-05_ep5_bs16_seed123\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr3e-05_ep5_bs16_seed2025\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4390' max='4390' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4390/4390 06:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.134000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.541300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.317700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.179600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.129400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.132600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.084700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.095100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.074700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.076200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.073600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.067500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.055700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.050400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.047100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.059100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.043200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.053800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.055500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.056300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.027000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.026200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>0.025200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>0.023500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>0.024600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>0.012400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.004800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.012100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3250</td>\n",
       "      <td>0.013800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3350</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3450</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3550</td>\n",
       "      <td>0.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3650</td>\n",
       "      <td>0.007500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3750</td>\n",
       "      <td>0.008600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3850</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.006200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3950</td>\n",
       "      <td>0.006300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.006600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4050</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.010600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4150</td>\n",
       "      <td>0.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.005200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4250</td>\n",
       "      <td>0.003000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.005400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4350</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='216' max='216' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [216/216 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.20234379172325134, 'eval_precision': 0.8907996560619088, 'eval_recall': 0.9177888022678952, 'eval_f1': 0.9040928527794746, 'eval_runtime': 5.1392, 'eval_samples_per_second': 671.889, 'eval_steps_per_second': 42.03, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr3e-05_ep5_bs16_seed2025.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr3e-05_ep5_bs16_seed2025\n",
      " Finished bert_lr3e-05_ep5_bs16_seed2025\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr2e-05_ep5_bs32_seed42\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 03:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.001400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.907200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.400800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.196400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.164800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.119100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.102900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.082700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.089100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.064900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.059400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.061500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.060700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.059600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.030700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.033500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.027200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.026300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.020800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.021600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.009400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.016400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.015100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.012000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.012900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.1754453331232071, 'eval_precision': 0.8804774083546462, 'eval_recall': 0.9149539333805812, 'eval_f1': 0.8973846554870101, 'eval_runtime': 3.7351, 'eval_samples_per_second': 924.469, 'eval_steps_per_second': 28.915, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr2e-05_ep5_bs32_seed42.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr2e-05_ep5_bs32_seed42\n",
      " Finished bert_lr2e-05_ep5_bs32_seed42\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr2e-05_ep5_bs32_seed123\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 04:01, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.873100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.840400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.368400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.187100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.154800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.118700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.101400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.078900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.088600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.064700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.066200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.062400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.055700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.057300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.036100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.031300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.033300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.028000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.033100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.028600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.016300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.023000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.018600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.019200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.015900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.013400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.011900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.013900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.012800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.17422156035900116, 'eval_precision': 0.8795632889798704, 'eval_recall': 0.9135364989369241, 'eval_f1': 0.8962280549278637, 'eval_runtime': 3.8566, 'eval_samples_per_second': 895.337, 'eval_steps_per_second': 28.004, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr2e-05_ep5_bs32_seed123.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr2e-05_ep5_bs32_seed123\n",
      " Finished bert_lr2e-05_ep5_bs32_seed123\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Starting run: bert_lr2e-05_ep5_bs32_seed2025\n",
      "\n",
      "Starting fine-tuning for bert-base-cased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\mbdn1\\AppData\\Local\\Temp\\ipykernel_12156\\934232259.py:97: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2195' max='2195' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2195/2195 03:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.910700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.376600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.193700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.162100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.119500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.101100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.083800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.088700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.066900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.064400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.061100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.060400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.057800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.057500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.056500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.034000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.030200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.031400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.032400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.034300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.025800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.022600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.018900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.021100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.010700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>0.017700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.014900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.014500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>0.012700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='108' max='108' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [108/108 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test metrics: {'eval_loss': 0.17149899899959564, 'eval_precision': 0.8843653780362641, 'eval_recall': 0.9160170092133239, 'eval_f1': 0.8999129677980853, 'eval_runtime': 3.2394, 'eval_samples_per_second': 1065.927, 'eval_steps_per_second': 33.339, 'epoch': 5.0}\n",
      "\n",
      "ðŸ’¾ Results saved to C:\\Users\\mbdn1\\results\\bert_lr2e-05_ep5_bs32_seed2025.json\n",
      "ðŸ’¾ Model saved to   C:\\Users\\mbdn1\\models\\bert_lr2e-05_ep5_bs32_seed2025\n",
      " Finished bert_lr2e-05_ep5_bs32_seed2025\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# Focused Fine-Tuning Loop (Top 4 Configs Ã— 3 Seeds)\n",
    "# ================================================\n",
    "from transformers import set_seed\n",
    "import os\n",
    "\n",
    "# Define top 4 best configurations from previous experiments\n",
    "top_configs = [\n",
    "    (5e-5, 5, 32),\n",
    "    (3e-5, 5, 32),\n",
    "    (3e-5, 5, 16),\n",
    "    (2e-5, 5, 32),\n",
    "]\n",
    "\n",
    "# Define seeds for reproducibility\n",
    "seeds = [42, 123, 2025]\n",
    "\n",
    "print(f\" Total runs: {len(top_configs)} Ã— {len(seeds)} = {len(top_configs) * len(seeds)} experiments\\n\")\n",
    "\n",
    "for lr, ep, bs in top_configs:\n",
    "    for seed in seeds:\n",
    "        set_seed(seed)\n",
    "\n",
    "        run_name = f\"bert_lr{lr:.0e}_ep{ep}_bs{bs}_seed{seed}\"\n",
    "\n",
    "        # Update config\n",
    "        experiment_config.update({\n",
    "            \"learning_rate\": lr,\n",
    "            \"num_epochs\": ep,\n",
    "            \"batch_size\": bs,\n",
    "            \"save_dir\": os.path.join(MODELS_DIR, run_name),\n",
    "            \"results_file\": os.path.join(RESULTS_DIR, f\"{run_name}.json\"),\n",
    "        })\n",
    "\n",
    "        print(f\"\\n Starting run: {run_name}\")\n",
    "        trainer, metrics = run_finetuning(experiment_config, tokenized_datasets)\n",
    "\n",
    "        # Add metadata\n",
    "        metrics[\"seed\"] = seed\n",
    "        metrics[\"learning_rate\"] = lr\n",
    "        metrics[\"epochs\"] = ep\n",
    "        metrics[\"batch_size\"] = bs\n",
    "        metrics[\"run_name\"] = run_name\n",
    "\n",
    "        # Save again with extended info\n",
    "        with open(experiment_config[\"results_file\"], \"w\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "\n",
    "        print(f\" Finished {run_name}\\n{'-'*80}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "febd6b55-580a-4474-94fe-b40519cda8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 experiment results.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_name</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>seed</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907789</td>\n",
       "      <td>0.894972</td>\n",
       "      <td>0.920978</td>\n",
       "      <td>0.185292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert_lr3e-05_ep5_bs32_seed2025</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>0.905325</td>\n",
       "      <td>0.889535</td>\n",
       "      <td>0.921687</td>\n",
       "      <td>0.176802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_lr3e-05_ep5_bs16_seed2025</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>0.904093</td>\n",
       "      <td>0.890800</td>\n",
       "      <td>0.917789</td>\n",
       "      <td>0.202344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903804</td>\n",
       "      <td>0.888413</td>\n",
       "      <td>0.919738</td>\n",
       "      <td>0.178844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903647</td>\n",
       "      <td>0.888109</td>\n",
       "      <td>0.919738</td>\n",
       "      <td>0.209742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903406</td>\n",
       "      <td>0.888470</td>\n",
       "      <td>0.918852</td>\n",
       "      <td>0.171244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.903401</td>\n",
       "      <td>0.891631</td>\n",
       "      <td>0.915485</td>\n",
       "      <td>0.174496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert_lr3e-05_ep5_bs16_seed42</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.903012</td>\n",
       "      <td>0.887710</td>\n",
       "      <td>0.918852</td>\n",
       "      <td>0.216410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902771</td>\n",
       "      <td>0.888070</td>\n",
       "      <td>0.917966</td>\n",
       "      <td>0.218571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.902269</td>\n",
       "      <td>0.888927</td>\n",
       "      <td>0.916017</td>\n",
       "      <td>0.197182</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         run_name  learning_rate  epochs  batch_size    seed  \\\n",
       "0                             NaN            NaN     NaN         NaN     NaN   \n",
       "1  bert_lr3e-05_ep5_bs32_seed2025        0.00003     5.0        32.0  2025.0   \n",
       "2  bert_lr3e-05_ep5_bs16_seed2025        0.00003     5.0        16.0  2025.0   \n",
       "3                             NaN            NaN     NaN         NaN     NaN   \n",
       "4                             NaN            NaN     NaN         NaN     NaN   \n",
       "5                             NaN            NaN     NaN         NaN     NaN   \n",
       "6                             NaN            NaN     NaN         NaN     NaN   \n",
       "7    bert_lr3e-05_ep5_bs16_seed42        0.00003     5.0        16.0    42.0   \n",
       "8                             NaN            NaN     NaN         NaN     NaN   \n",
       "9                             NaN            NaN     NaN         NaN     NaN   \n",
       "\n",
       "    eval_f1  eval_precision  eval_recall  eval_loss  \n",
       "0  0.907789        0.894972     0.920978   0.185292  \n",
       "1  0.905325        0.889535     0.921687   0.176802  \n",
       "2  0.904093        0.890800     0.917789   0.202344  \n",
       "3  0.903804        0.888413     0.919738   0.178844  \n",
       "4  0.903647        0.888109     0.919738   0.209742  \n",
       "5  0.903406        0.888470     0.918852   0.171244  \n",
       "6  0.903401        0.891631     0.915485   0.174496  \n",
       "7  0.903012        0.887710     0.918852   0.216410  \n",
       "8  0.902771        0.888070     0.917966   0.218571  \n",
       "9  0.902269        0.888927     0.916017   0.197182  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“ˆ Summary by configuration (averaged over seeds):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>f1_mean</th>\n",
       "      <th>f1_std</th>\n",
       "      <th>precision_mean</th>\n",
       "      <th>recall_mean</th>\n",
       "      <th>loss_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.9014</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>0.1804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00003</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.9011</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>0.2102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>0.1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.8978</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.8815</td>\n",
       "      <td>0.9148</td>\n",
       "      <td>0.1737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   learning_rate  epochs  batch_size  f1_mean  f1_std  precision_mean  \\\n",
       "0        0.00003     5.0        32.0   0.9014  0.0039          0.8851   \n",
       "1        0.00003     5.0        16.0   0.9011  0.0043          0.8860   \n",
       "2        0.00005     5.0        32.0   0.8986  0.0005          0.8826   \n",
       "3        0.00002     5.0        32.0   0.8978  0.0019          0.8815   \n",
       "\n",
       "   recall_mean  loss_mean  \n",
       "0       0.9183     0.1804  \n",
       "1       0.9168     0.2102  \n",
       "2       0.9151     0.1867  \n",
       "3       0.9148     0.1737  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\ Summary saved to: C:\\Users\\mbdn1\\results\\summary_across_seeds.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# ðŸ“Š Aggregate and Compare Results\n",
    "# ================================================\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Load all JSON result files from results directory\n",
    "result_files = glob(os.path.join(RESULTS_DIR, \"bert_*.json\"))\n",
    "\n",
    "results = []\n",
    "for fpath in result_files:\n",
    "    with open(fpath, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "        data[\"file_name\"] = os.path.basename(fpath)\n",
    "        results.append(data)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Keep only relevant columns\n",
    "metrics_cols = [\"run_name\", \"learning_rate\", \"epochs\", \"batch_size\", \"seed\",\n",
    "                \"eval_f1\", \"eval_precision\", \"eval_recall\", \"eval_loss\"]\n",
    "df = df[metrics_cols]\n",
    "\n",
    "# Sort by F1 descending\n",
    "df = df.sort_values(by=\"eval_f1\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} experiment results.\\n\")\n",
    "display(df.head(10))\n",
    "\n",
    "# Group by hyperparameters to compute mean/variance across seeds\n",
    "summary = (\n",
    "    df.groupby([\"learning_rate\", \"epochs\", \"batch_size\"])\n",
    "      .agg({\n",
    "          \"eval_f1\": [\"mean\", \"std\"],\n",
    "          \"eval_precision\": \"mean\",\n",
    "          \"eval_recall\": \"mean\",\n",
    "          \"eval_loss\": \"mean\"\n",
    "      })\n",
    "      .round(4)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "summary.columns = [\"learning_rate\", \"epochs\", \"batch_size\", \n",
    "                   \"f1_mean\", \"f1_std\", \"precision_mean\", \"recall_mean\", \"loss_mean\"]\n",
    "\n",
    "print(\"\\nðŸ“ˆ Summary by configuration (averaged over seeds):\")\n",
    "display(summary.sort_values(by=\"f1_mean\", ascending=False).reset_index(drop=True))\n",
    "\n",
    "# Save summary to a CSV file for convenience\n",
    "summary_path = os.path.join(RESULTS_DIR, \"summary_across_seeds.csv\")\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(f\"\\ Summary saved to: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53dc25ce-bdde-46fc-bfd3-3994eb514fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.bar(summary[\"learning_rate\"].astype(str) + \"_bs\" + summary[\"batch_size\"].astype(str),\n",
    "        summary[\"f1_mean\"], yerr=summary[\"f1_std\"], capsize=5)\n",
    "plt.title(\"F1 Score (Mean Â± Std) Across Configurations\")\n",
    "plt.xlabel(\"Learning Rate + Batch Size\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d903c11-6452-45b1-ad6d-dfa0c60f2472",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
